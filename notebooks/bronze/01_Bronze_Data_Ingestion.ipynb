{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619bdfd0-c662-4b79-8afb-ed6b20f95202",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 01 - Bronze Data Ingestion\n",
    "\n",
    "**Purpose:** Ingest raw market data from Yahoo Finance and Alpha Vantage APIs\n",
    "\n",
    "**Author:** Jonah A.\n",
    "**Created:** 2025-07-29\n",
    "\n",
    "**Architecture Layer:** Bronze (Raw Data)\n",
    "\n",
    "**Input:** Market APIs (Yahoo Finance, Alpha Vantage)  \n",
    "**Output:** `bronze_market_data_raw` Delta table\n",
    "\n",
    "**Business Value:** Foundation for AI portfolio risk analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed726b6d-2f4c-4620-8b3a-e5f17035efd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# PURPOSE: Configure API credentials and security settings\n",
    "# DEPENDENCIES: None (foundational setup)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load API configuration securely\n",
    "try:\n",
    "    # For Databricks: Use secrets scope (preferred for production)\n",
    "    ALPHA_VANTAGE_API_KEY = dbutils.secrets.get(scope=\"market-risk\", key=\"alpha_vantage_api_key\")\n",
    "    print(\"‚úÖ Using Databricks secrets\")\n",
    "except:\n",
    "    # Fallback: Use a default for development (will be replaced by proper secrets)\n",
    "    ALPHA_VANTAGE_API_KEY = \"5BNQA7JVK3N8FAMO\"\n",
    "    print(\"‚ö†Ô∏è Using fallback API key - set up Databricks secrets for production\")\n",
    "\n",
    "ALPHA_VANTAGE_BASE_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "# Portfolio configuration\n",
    "portfolio_config = {\n",
    "    \"tier_1\": [\"NVDA\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"AAPL\"],\n",
    "    \"tier_2\": [\"AMD\", \"CRM\", \"ORCL\"], \n",
    "    \"tier_3\": [\"PLTR\", \"AI\", \"SNOW\", \"MDB\", \"SMCI\"],\n",
    "    \"benchmark\": [\"BOTZ\"]\n",
    "}\n",
    "\n",
    "# Flatten all symbols for processing\n",
    "all_symbols = []\n",
    "for tier_symbols in portfolio_config.values():\n",
    "    all_symbols.extend(tier_symbols)\n",
    "\n",
    "print(f\"üìä Portfolio configured: {len(all_symbols)} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2afaa78a-c60f-4d3d-8eed-d9ad6ee4d3d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LIBRARY IMPORTS\n",
    "# PURPOSE: Install required packages and import necessary libraries\n",
    "# DEPENDENCIES: None (foundational setup)\n",
    "# =============================================================================\n",
    "\n",
    "%pip install yfinance requests\n",
    "\n",
    "# Import libraries\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from pyspark.sql import functions as F, Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, TimestampType\n",
    "import json\n",
    "\n",
    "print(\"üìö Libraries imported:\")\n",
    "print(\"‚úÖ yfinance - for Yahoo Finance historical data\")\n",
    "print(\"‚úÖ requests - for Alpha Vantage API calls\")\n",
    "print(\"‚úÖ pyspark.sql - for Delta Lake operations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c3c915a-9c74-427e-b841-99fe25df5d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATE CONFUGURATION\n",
    "# PURPOSE: Define historical data date range for 1+ year analysis\n",
    "# DEPENDENCIES: datetime libraries from Cell 1\n",
    "# =============================================================================\n",
    "\n",
    "# Historical data range (1+ year for risk analysis)\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=365)  # 1 year of data\n",
    "\n",
    "print(f\"üìÖ Historical Data Range:\")\n",
    "print(f\"Start Date: {start_date}\")\n",
    "print(f\"End Date: {end_date}\")\n",
    "print(f\"Total Period: {(end_date - start_date).days} days\")\n",
    "\n",
    "# Convert to string format for yfinance\n",
    "start_date_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "end_date_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"API Format: {start_date_str} to {end_date_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31818df2-89ba-4cb1-a32f-99b86c48255c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BULK HISTORICAL DOWNLOAD\n",
    "# PURPOSE: Download 1+ year of historical data for multiple stocks efficiently\n",
    "# DEPENDENCIES: yfinance from Cell 2, date configuration from Cell 3, portfolio from Cell 1\n",
    "# =============================================================================\n",
    "\n",
    "# Historical data bulk download function\n",
    "def download_bulk_historical_data(symbols, start_date, end_date):\n",
    "    \"\"\"Download historical data for multiple symbols efficiently\"\"\"\n",
    "    \n",
    "    print(f\"üì• Starting bulk download:\")\n",
    "    print(f\"Symbols: {len(symbols)} stocks\")\n",
    "    print(f\"Period: {start_date} to {end_date}\")\n",
    "    print(f\"Expected trading days: ~{(end_date - start_date).days * 5/7:.0f}\")\n",
    "    \n",
    "    # Use yfinance bulk download (more efficient than individual calls)\n",
    "    try:\n",
    "        historical_data = yf.download(\n",
    "            symbols, \n",
    "            start=start_date, \n",
    "            end=end_date,\n",
    "            group_by='ticker',\n",
    "            progress=True\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Bulk download completed successfully\")\n",
    "        print(f\"Data shape: {historical_data.shape}\")\n",
    "        return historical_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Bulk download failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with first 3 stocks before scaling to all 15\n",
    "test_symbols = [\"AAPL\", \"NVDA\", \"MSFT\"]\n",
    "print(f\"üß™ Testing bulk download with {len(test_symbols)} stocks for 1 year...\")\n",
    "\n",
    "# Download historical data\n",
    "historical_data = download_bulk_historical_data(test_symbols, start_date, end_date)\n",
    "\n",
    "if historical_data is not None:\n",
    "    print(f\"üìä Sample data structure:\")\n",
    "    print(f\"Columns: {historical_data.columns.names}\")\n",
    "    print(f\"Sample data for AAPL:\")\n",
    "    print(historical_data['AAPL'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5878cae6-37ca-40bf-9f5a-ee76f090675f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BRONZE SCHEMA DEFINITION\n",
    "# PURPOSE: Define Delta Lake schema for Bronze layer immutable storage\n",
    "# DEPENDENCIES: PySpark data types from Cell 2\n",
    "# =============================================================================\n",
    "\n",
    "# Bronze layer schema: immutable raw data storage\n",
    "# Supports both Yahoo Finance and Alpha Vantage data sources\n",
    "bronze_schema = StructType([\n",
    "    StructField(\"ingestion_timestamp\", TimestampType(), True),  # When data was ingested\n",
    "    StructField(\"symbol\", StringType(), True),                 # Stock ticker (AAPL, NVDA, etc.)\n",
    "    StructField(\"date\", StringType(), True),                   # Trading date\n",
    "    StructField(\"open\", DoubleType(), True),                   # Opening price\n",
    "    StructField(\"high\", DoubleType(), True),                   # Daily high price\n",
    "    StructField(\"low\", DoubleType(), True),                    # Daily low price\n",
    "    StructField(\"close\", DoubleType(), True),                  # Closing price\n",
    "    StructField(\"volume\", LongType(), True),                   # Trading volume\n",
    "    StructField(\"data_source\", StringType(), True)             # yahoo_finance | alpha_vantage\n",
    "])\n",
    "\n",
    "# TODO: Remove before production - development feedback only\n",
    "print(\"üèóÔ∏è Bronze schema defined with 9 fields\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a09647cd-d818-4825-9346-521e38c0e72c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BRONZE DATA PROCESSING & TEMPORARY VIEW CREATION\n",
    "# PURPOSE: Transform historical market data into Bronze layer format and create queryable view\n",
    "# DEPENDENCIES: historical_data (Cell 4), conversion function (Cell 6), bronze_schema (Cell 5)\n",
    "# =============================================================================\n",
    "\n",
    "# Process the full historical dataset (250 days √ó 3 stocks)\n",
    "print(\"üîÑ Processing full historical dataset...\")\n",
    "print(f\"Historical data shape: {historical_data.shape}\")\n",
    "\n",
    "# Process each stock from the historical dataset\n",
    "all_bronze_rows = []\n",
    "ingestion_time = datetime.now()\n",
    "\n",
    "for symbol in [\"AAPL\", \"NVDA\", \"MSFT\"]:\n",
    "    print(f\"Processing {symbol}...\")\n",
    "    stock_data = historical_data[symbol]  # Get data for this stock\n",
    "    \n",
    "    # Convert each row to Bronze format (handle multi-stock download structure)\n",
    "    for date_idx, row in stock_data.iterrows():\n",
    "        bronze_row = Row(\n",
    "            ingestion_timestamp=ingestion_time,\n",
    "            symbol=symbol,\n",
    "            date=str(date_idx.date()),\n",
    "            open=float(row['Open']),      # Simple column access for multi-stock download\n",
    "            high=float(row['High']),\n",
    "            low=float(row['Low']),\n",
    "            close=float(row['Close']),\n",
    "            volume=int(row['Volume']),\n",
    "            data_source=\"yahoo_finance\"\n",
    "        )\n",
    "        all_bronze_rows.append(bronze_row)\n",
    "    \n",
    "    print(f\"  ‚úÖ {len(stock_data)} rows processed for {symbol}\")\n",
    "\n",
    "print(f\"\\nüìä Total Bronze rows: {len(all_bronze_rows)}\")\n",
    "\n",
    "# Create PySpark DataFrame and temporary view\n",
    "bronze_df = spark.createDataFrame(all_bronze_rows, bronze_schema)\n",
    "bronze_df.createOrReplaceTempView(\"bronze_market_data\")\n",
    "\n",
    "# Validation\n",
    "row_count = bronze_df.count()\n",
    "print(f\"‚úÖ Bronze temporary view created with {row_count} rows\")\n",
    "\n",
    "# Sample data verification\n",
    "print(\"\\nüìà Sample Bronze data:\")\n",
    "bronze_df.select(\"symbol\", \"date\", \"close\", \"data_source\").orderBy(\"symbol\", \"date\").show(6)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Bronze_Data_Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
