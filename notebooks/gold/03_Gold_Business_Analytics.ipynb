{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb35c609-8844-4869-b17a-e941be7a1f27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 03 - Gold Business Analytics\n",
    "\n",
    "**Purpose:** Generate portfolio risk metrics and business analytics from Silver layer data\n",
    "\n",
    "**Author:** Jonah A.  \n",
    "**Created:** 2025-07-30\n",
    "\n",
    "**Architecture Layer:** Gold (Business Analytics)\n",
    "\n",
    "**Input:** Silver layer enhanced view `silver_daily_prices_enhanced`  \n",
    "**Output:** Portfolio risk metrics, VaR calculations, and business insights\n",
    "\n",
    "**Business Value:** Investment risk analysis and portfolio monitoring for AI stock portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d86338-4edb-4238-9c6f-ba14b9a5b2af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Recreate complete pipeline with fixed column references\n",
    "%pip install yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "from pyspark.sql import Row, functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"üîÑ Recreating Bronze ‚Üí Silver pipeline (fixed)...\")\n",
    "\n",
    "# Step 1: Download AAPL data\n",
    "test_data = yf.download(\"AAPL\", period=\"5d\")\n",
    "\n",
    "# Step 2: Convert to Bronze format\n",
    "bronze_rows = []\n",
    "ingestion_time = datetime.now()\n",
    "\n",
    "for date_idx, row in test_data.iterrows():\n",
    "    bronze_row = Row(\n",
    "        symbol=\"AAPL\",\n",
    "        trading_date=date_idx.date(),  # Use proper date from start\n",
    "        open=float(row[('Open', 'AAPL')]),\n",
    "        high=float(row[('High', 'AAPL')]),\n",
    "        low=float(row[('Low', 'AAPL')]),\n",
    "        close=float(row[('Close', 'AAPL')]),\n",
    "        volume=int(row[('Volume', 'AAPL')]),\n",
    "        data_source=\"yahoo_finance\"\n",
    "    )\n",
    "    bronze_rows.append(bronze_row)\n",
    "\n",
    "# Step 3: Create Silver with proper schema\n",
    "bronze_schema = StructType([\n",
    "    StructField(\"symbol\", StringType(), True),\n",
    "    StructField(\"trading_date\", DateType(), True),  # Proper date type\n",
    "    StructField(\"open\", DoubleType(), True),\n",
    "    StructField(\"high\", DoubleType(), True),\n",
    "    StructField(\"low\", DoubleType(), True),\n",
    "    StructField(\"close\", DoubleType(), True),\n",
    "    StructField(\"volume\", LongType(), True),\n",
    "    StructField(\"data_source\", StringType(), True)\n",
    "])\n",
    "\n",
    "bronze_df = spark.createDataFrame(bronze_rows, bronze_schema)\n",
    "\n",
    "# Silver transformation with correct column references\n",
    "window_spec = Window.partitionBy(\"symbol\").orderBy(\"trading_date\")\n",
    "\n",
    "silver_df = bronze_df.select(\n",
    "    F.col(\"symbol\"),\n",
    "    F.col(\"trading_date\"),\n",
    "    F.round(F.col(\"close\"), 2).alias(\"close_price\"),\n",
    "    F.col(\"volume\").alias(\"trading_volume\")\n",
    ").withColumn(\n",
    "    \"daily_return_pct\", \n",
    "    F.round(\n",
    "        ((F.col(\"close_price\") - F.lag(\"close_price\").over(window_spec)) \n",
    "         / F.lag(\"close_price\").over(window_spec) * 100), 4\n",
    "    )\n",
    ").orderBy(\"trading_date\")\n",
    "\n",
    "silver_df.createOrReplaceTempView(\"silver_for_gold\")\n",
    "\n",
    "print(\"‚úÖ Fixed Silver data ready:\")\n",
    "silver_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a965c684-45db-4460-a48c-33d7b34d9e0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gold layer risk analytics\n",
    "silver_df = spark.table(\"silver_for_gold\")\n",
    "\n",
    "# Calculate key risk metrics (excluding NULL values)\n",
    "risk_metrics = silver_df.filter(F.col(\"daily_return_pct\").isNotNull()).agg(\n",
    "    F.avg(\"daily_return_pct\").alias(\"avg_daily_return\"),\n",
    "    F.stddev(\"daily_return_pct\").alias(\"daily_volatility\"),\n",
    "    F.min(\"daily_return_pct\").alias(\"worst_daily_return\"),\n",
    "    F.max(\"daily_return_pct\").alias(\"best_daily_return\"),\n",
    "    F.count(\"daily_return_pct\").alias(\"trading_days\")\n",
    ").collect()[0]\n",
    "\n",
    "print(\"üìä AAPL Risk Profile (4-day sample):\")\n",
    "print(f\"Average Daily Return: {risk_metrics['avg_daily_return']:.4f}%\")\n",
    "print(f\"Daily Volatility: {risk_metrics['daily_volatility']:.4f}%\")\n",
    "print(f\"Best Day: +{risk_metrics['best_daily_return']:.4f}%\")\n",
    "print(f\"Worst Day: {risk_metrics['worst_daily_return']:.4f}%\")\n",
    "print(f\"Trading Days Analyzed: {risk_metrics['trading_days']}\")\n",
    "\n",
    "# Annualized metrics (standard financial industry calculation)\n",
    "annual_return = risk_metrics['avg_daily_return'] * 252  # 252 trading days/year\n",
    "annual_volatility = risk_metrics['daily_volatility'] * (252 ** 0.5)  # Square root of time scaling\n",
    "\n",
    "print(f\"\\nüìà Annualized Risk Estimates:\")\n",
    "print(f\"Expected Annual Return: {annual_return:.2f}%\")\n",
    "print(f\"Annual Volatility: {annual_volatility:.2f}%\")\n",
    "\n",
    "# Risk-adjusted metrics\n",
    "if annual_volatility > 0:\n",
    "    sharpe_estimate = annual_return / annual_volatility  # Simplified Sharpe ratio (assuming 0% risk-free rate)\n",
    "    print(f\"Risk-Adjusted Return Ratio: {sharpe_estimate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ef1ddf7-f059-446f-aa6c-7722059e253c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Gold layer business summary\n",
    "portfolio_summary = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        symbol,\n",
    "        MIN(trading_date) as period_start,\n",
    "        MAX(trading_date) as period_end,\n",
    "        ROUND(MIN(close_price), 2) as period_low,\n",
    "        ROUND(MAX(close_price), 2) as period_high,\n",
    "        ROUND(FIRST(close_price), 2) as period_open,\n",
    "        ROUND(LAST(close_price), 2) as period_close,\n",
    "        ROUND(((LAST(close_price) - FIRST(close_price)) / FIRST(close_price) * 100), 2) as total_return_pct,\n",
    "        ROUND(AVG(trading_volume), 0) as avg_daily_volume\n",
    "    FROM silver_for_gold \n",
    "    WHERE trading_date IS NOT NULL\n",
    "    GROUP BY symbol\n",
    "    ORDER BY symbol\n",
    "\"\"\")\n",
    "\n",
    "print(\"üìà Gold Layer Portfolio Summary:\")\n",
    "portfolio_summary.show()\n",
    "\n",
    "# Create final Gold table for business users\n",
    "portfolio_summary.createOrReplaceTempView(\"gold_portfolio_summary\")\n",
    "\n",
    "print(\"‚úÖ Gold layer complete - Business analytics ready for executives\")\n",
    "print(\"\\nüéØ Business Insight:\")\n",
    "total_return = portfolio_summary.collect()[0]['total_return_pct']\n",
    "if total_return > 0:\n",
    "    print(f\"‚úÖ AAPL gained {total_return}% over the analysis period\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  AAPL declined {abs(total_return)}% over the analysis period\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Gold_Business_Analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
